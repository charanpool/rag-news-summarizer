# ğŸ“° RAG News Summarizer

[![Python 3.10+](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![LangChain](https://img.shields.io/badge/LangChain-0.3-green.svg)](https://langchain.com/)
[![Ollama](https://img.shields.io/badge/Ollama-Local%20LLM-purple.svg)](https://ollama.ai/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](CONTRIBUTING.md)

> **A Retrieval-Augmented Generation (RAG) system for fetching, indexing, and summarizing news articles using local AI models.**

RAG News Summarizer demonstrates a complete RAG pipeline â€” from data ingestion to semantic search to LLM-powered summarization â€” all running locally on your machine.

---

## ğŸŒ± Why This Project Exists

This project was **intentionally built as a simple, educational implementation** of RAG concepts.

Modern AI applications increasingly rely on RAG architectures, but many tutorials are either:
- Too abstract (theory without working code)
- Too complex (production systems with overwhelming features)
- Cloud-dependent (requiring API keys and paid services)

**RAG News Summarizer** fills the gap by providing:

- âœ… A **complete, working implementation** you can run locally
- âœ… **Clean, readable code** that's easy to understand and modify
- âœ… **No API keys required** â€” uses local models only
- âœ… A **foundation to build upon** for your own projects

This is ideal for learning, portfolio projects, or as a starting point for production systems.

---

## âœ¨ Features

- ğŸ” **Semantic Search** â€” Find relevant articles using vector similarity
- ğŸ“° **Multi-Source Ingestion** â€” Fetches from BBC, Reuters, TechCrunch, and more
- ğŸ¤– **Local LLM Integration** â€” Runs entirely on your machine with Ollama
- ğŸ’¾ **Persistent Storage** â€” ChromaDB vector database for efficient retrieval
- ğŸ¨ **Modern Web UI** â€” Beautiful Streamlit interface with real-time updates
- ğŸ”’ **Privacy-First** â€” No data leaves your machine

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Streamlit Web UI                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   RAG Pipeline (LangChain)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ News Fetcher  â”‚  â”‚ Vector Store   â”‚  â”‚ LLM Chain          â”‚  â”‚
â”‚  â”‚ (RSS Parser)  â”‚  â”‚ (ChromaDB)     â”‚  â”‚ (Ollama)           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚                    â”‚
         â–¼                    â–¼                    â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ RSS Feedsâ”‚      â”‚ Sentence     â”‚      â”‚ Ollama      â”‚
   â”‚ (Free)   â”‚      â”‚ Transformers â”‚      â”‚ (Llama 3.2) â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

For detailed architecture documentation, see [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md).

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10 or higher
- [Ollama](https://ollama.ai/) installed

### Installation

```bash
# 1. Clone the repository
git clone https://github.com/charanpool/rag-news-summarizer.git
cd rag-news-summarizer

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Set up Ollama (in a separate terminal)
ollama pull llama3.2
ollama serve

# 5. Run the application
streamlit run app/main.py
```

Open your browser at `http://localhost:8501` ğŸ‰

### First Run

1. Click **"ğŸ”„ Fetch & Index News"** in the sidebar
2. Wait for articles to be fetched and indexed
3. Ask a question like *"What's the latest in AI?"*
4. View the AI-generated summary with source citations

---

## ğŸ“ Project Structure

```
RAG_News_Summarizer/
â”œâ”€â”€ app/                    # Application code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py           # Configuration settings
â”‚   â”œâ”€â”€ embeddings.py       # Embedding generation
â”‚   â”œâ”€â”€ main.py             # Streamlit web interface
â”‚   â”œâ”€â”€ news_fetcher.py     # RSS feed parser
â”‚   â”œâ”€â”€ rag_chain.py        # RAG pipeline logic
â”‚   â””â”€â”€ vector_store.py     # ChromaDB operations
â”œâ”€â”€ data/                   # Runtime data (gitignored)
â”‚   â””â”€â”€ chroma_db/          # Vector database storage
â”œâ”€â”€ docs/                   # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md     # Technical architecture
â”‚   â””â”€â”€ CONCEPTS.md         # Core RAG concepts
â”œâ”€â”€ tests/                  # Test suite
â”‚   â””â”€â”€ test_rag.py
â”œâ”€â”€ .env.example            # Environment template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ CONTRIBUTING.md         # Contribution guidelines
â”œâ”€â”€ LICENSE                 # MIT License
â”œâ”€â”€ README.md               # This file
â”œâ”€â”€ ROADMAP.md              # Future enhancement plans
â””â”€â”€ requirements.txt        # Python dependencies
```

---

## ğŸ› ï¸ Tech Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Orchestration** | LangChain | RAG pipeline framework |
| **Embeddings** | sentence-transformers | Text vectorization (local) |
| **Vector DB** | ChromaDB | Similarity search storage |
| **LLM** | Ollama (Llama 3.2) | Text generation (local) |
| **Web UI** | Streamlit | Interactive interface |
| **News Source** | RSS Feeds | Free news data |

---

## ğŸ“Š How It Works

### 1. Ingestion Phase

```
RSS Feeds â†’ Parse Articles â†’ Chunk Text â†’ Generate Embeddings â†’ Store in ChromaDB
```

### 2. Query Phase

```
User Query â†’ Embed Query â†’ Semantic Search â†’ Retrieve Top-K Articles
```

### 3. Generation Phase

```
Retrieved Context + User Query â†’ LLM Prompt â†’ Generated Summary â†’ Display
```

For a deeper dive, see [docs/CONCEPTS.md](docs/CONCEPTS.md).

---

## âš™ï¸ Configuration

Key settings in `app/config.py`:

| Setting | Default | Description |
|---------|---------|-------------|
| `EMBEDDING_MODEL` | `all-MiniLM-L6-v2` | Sentence-transformer model |
| `OLLAMA_MODEL` | `llama3.2` | Local LLM model |
| `CHUNK_SIZE` | `1000` | Text chunk size (characters) |
| `CHUNK_OVERLAP` | `200` | Overlap between chunks |
| `TOP_K_RESULTS` | `5` | Documents to retrieve |

Override via `.env` file:

```bash
cp .env.example .env
# Edit .env with your preferences
```

---

## ğŸ“¡ Supported News Sources

| Source | Category |
|--------|----------|
| BBC World | World News |
| BBC Tech | Technology |
| Reuters | World News |
| TechCrunch | Technology |
| Hacker News | Technology |
| Ars Technica | Technology |

Add custom sources in `app/config.py`:

```python
RSS_FEEDS = {
    "Your Source": "https://example.com/rss/feed.xml",
}
```

---

## ğŸ§ª Running Tests

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=app --cov-report=html
```

---

## ğŸ§© Design Principles

This project follows intentionally **lean design principles**:

| Principle | Implementation |
|-----------|----------------|
| **Simplicity** | Minimal dependencies, clear code structure |
| **Local-First** | No external API calls required |
| **Educational** | Well-documented, easy to understand |
| **Extensible** | Clean abstractions for modification |
| **Stateless Core** | No database beyond vector store |

### Keeping It Simple

This project skips a few things on purpose to stay beginner-friendly:

- User authentication
- Cloud deployments
- Complex caching layers
- Microservices architecture
- Kubernetes configurations

Want to add these? Check out [ROADMAP.md](ROADMAP.md) for ideas!

---

## ğŸ”§ Troubleshooting

### Ollama Not Running

```bash
# Start Ollama server
ollama serve

# Verify it's running
curl http://localhost:11434/api/tags
```

### Model Not Found

```bash
# Pull the required model
ollama pull llama3.2
```

### Memory Issues

- Use a smaller embedding model in config
- Reduce `CHUNK_SIZE`
- Use a smaller Ollama model: `llama3.2:1b`

### Module Import Errors

Ensure you're running from the project root:

```bash
cd /path/to/RAG_News_Summarizer
source venv/bin/activate
streamlit run app/main.py
```

---

## ğŸ“– Documentation

| Document | Description |
|----------|-------------|
| [CONCEPTS.md](docs/CONCEPTS.md) | Core RAG concepts explained |
| [ARCHITECTURE.md](docs/ARCHITECTURE.md) | Technical architecture details |
| [ROADMAP.md](ROADMAP.md) | Future enhancement plans |
| [CONTRIBUTING.md](CONTRIBUTING.md) | How to contribute |

---

## ğŸ¤ Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

Areas where help is appreciated:
- Improving heuristic parsing
- Adding test fixtures
- Documentation improvements
- UI/UX enhancements

---

## ğŸ—ºï¸ Roadmap

See [ROADMAP.md](ROADMAP.md) for planned features including:

- [ ] Hybrid search (semantic + keyword)
- [ ] Multiple LLM provider support
- [ ] REST API endpoints
- [ ] Docker containerization
- [ ] Enhanced UI features

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

- âœ… Free for personal and commercial use
- âœ… Modify and distribute freely
- âœ… Attribution required

---

## ğŸ™ Acknowledgments

- [LangChain](https://langchain.com/) â€” RAG framework
- [Ollama](https://ollama.ai/) â€” Local LLM inference
- [ChromaDB](https://www.trychroma.com/) â€” Vector storage
- [Sentence-Transformers](https://www.sbert.net/) â€” Embeddings
- [Streamlit](https://streamlit.io/) â€” Web interface

---

## â­ Support

If you find this project useful:

- â­ **Star** the repository
- ğŸ› **Report** issues you encounter
- ğŸ’¡ **Share** ideas for improvements
- ğŸ§‘â€ğŸ’» **Contribute** code or documentation

---

<p align="center">
  Built with â¤ï¸ for learning and demonstration purposes
</p>
